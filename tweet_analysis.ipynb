{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import csv\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.read_parquet('/Users/Owner/OneDrive/Desktop/DS_project/Nov_Data_merged.parquet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_pipeline = pipeline(\"text-classification\", model=\"seantw/covid-19-vaccination-tweet-relevance\")\n",
    "\n",
    "sentiment_pipeline = pipeline(\"text-classification\", model=\"seantw/covid-19-vaccination-tweet-stance\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @Eric_Schmitt: In other news: Missouri to file lawsuit challenging said “emergency vaccine rule for large employers” in the coming days.…\n",
      "1142422\n",
      "1142422\n"
     ]
    }
   ],
   "source": [
    "# Automating\n",
    "\n",
    "def data_split(data, col_name, x):\n",
    "    split_size = len(data) // x\n",
    "    \n",
    "    # Initialize a list to store the split DataFrames\n",
    "    split_dfs = []\n",
    "    \n",
    "    # Split the DataFrame into x number of DataFrames\n",
    "    for i in range(x - 1):\n",
    "        start_index = i * split_size\n",
    "        end_index = (i + 1) * split_size\n",
    "        split_df = data.iloc[start_index:end_index, :]\n",
    "        split_dfs.append(split_df[col_name].tolist())\n",
    "    \n",
    "    # Last DataFrame contains remaining rows\n",
    "    split_dfs.append(data.iloc[(x - 1) * split_size:, :][col_name].tolist())\n",
    "    \n",
    "    return split_dfs\n",
    "\n",
    "\n",
    "split_dataframes = data_split(full_data, 'text', 20)\n",
    "\n",
    "print(split_dataframes[1][1])\n",
    "check = sum(len(subject) for subject in split_dataframes)\n",
    "print(check)\n",
    "print(len(full_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply relevance pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =  relevance_pipeline(split_dataframes[0])\n",
    "\n",
    "labels = []\n",
    "\n",
    "for dict in results:\n",
    "    labels.append(dict['label'])\n",
    "\n",
    "file = open(\"/Users/Owner/OneDrive/Desktop/DS_project/split_dataframe_0.csv\", 'w+', newline ='')\n",
    "\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    for prediction in labels:\n",
    "        writer.writerow([prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =  relevance_pipeline(split_dataframes[1])\n",
    "\n",
    "labels = []\n",
    "\n",
    "for dict in results:\n",
    "    labels.append(dict['label'])\n",
    "\n",
    "file = open(\"/Users/Owner/OneDrive/Desktop/DS_project/split_dataframe_1.csv\", 'w+', newline ='')\n",
    "\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    for prediction in labels:\n",
    "        writer.writerow([prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =  relevance_pipeline(split_dataframes[2])\n",
    "\n",
    "labels = []\n",
    "\n",
    "for dict in results:\n",
    "    labels.append(dict['label'])\n",
    "\n",
    "file = open(\"/Users/Owner/OneDrive/Desktop/DS_project/split_dataframe_2.csv\", 'w+', newline ='')\n",
    "\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    for prediction in labels:\n",
    "        writer.writerow([prediction])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =  relevance_pipeline(split_dataframes[3])\n",
    "\n",
    "labels = []\n",
    "\n",
    "for dict in results:\n",
    "    labels.append(dict['label'])\n",
    "\n",
    "file = open(\"/Users/Owner/OneDrive/Desktop/DS_project/split_dataframe_3.csv\", 'w+', newline ='')\n",
    "\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    for prediction in labels:\n",
    "        writer.writerow([prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =  relevance_pipeline(split_dataframes[4])\n",
    "\n",
    "labels = []\n",
    "\n",
    "for dict in results:\n",
    "    labels.append(dict['label'])\n",
    "\n",
    "file = open(\"/Users/Owner/OneDrive/Desktop/DS_project/split_dataframe_4.csv\", 'w+', newline ='')\n",
    "\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    for prediction in labels:\n",
    "        writer.writerow([prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =  relevance_pipeline(split_dataframes[5])\n",
    "\n",
    "labels = []\n",
    "\n",
    "for dict in results:\n",
    "    labels.append(dict['label'])\n",
    "\n",
    "file = open(\"/Users/Owner/OneDrive/Desktop/DS_project/split_dataframe_5.csv\", 'w+', newline ='')\n",
    "\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    for prediction in labels:\n",
    "        writer.writerow([prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =  relevance_pipeline(split_dataframes[6])\n",
    "\n",
    "labels = []\n",
    "\n",
    "for dict in results:\n",
    "    labels.append(dict['label'])\n",
    "\n",
    "file = open(\"/Users/Owner/OneDrive/Desktop/DS_project/split_dataframe_6.csv\", 'w+', newline ='')\n",
    "\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    for prediction in labels:\n",
    "        writer.writerow([prediction])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =  relevance_pipeline(split_dataframes[7])\n",
    "\n",
    "labels = []\n",
    "\n",
    "for dict in results:\n",
    "    labels.append(dict['label'])\n",
    "\n",
    "file = open(\"/Users/Owner/OneDrive/Desktop/DS_project/split_dataframe_7.csv\", 'w+', newline ='')\n",
    "\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    for prediction in labels:\n",
    "        writer.writerow([prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =  relevance_pipeline(split_dataframes[8])\n",
    "\n",
    "labels = []\n",
    "\n",
    "for dict in results:\n",
    "    labels.append(dict['label'])\n",
    "\n",
    "file = open(\"/Users/Owner/OneDrive/Desktop/DS_project/split_dataframe_8.csv\", 'w+', newline ='')\n",
    "\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    for prediction in labels:\n",
    "        writer.writerow([prediction])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =  relevance_pipeline(split_dataframes[9])\n",
    "\n",
    "labels = []\n",
    "\n",
    "for dict in results:\n",
    "    labels.append(dict['label'])\n",
    "\n",
    "file = open(\"/Users/Owner/OneDrive/Desktop/DS_project/split_dataframe_9.csv\", 'w+', newline ='')\n",
    "\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    for prediction in labels:\n",
    "        writer.writerow([prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =  relevance_pipeline(split_dataframes[10])\n",
    "\n",
    "labels = []\n",
    "\n",
    "for dict in results:\n",
    "    labels.append(dict['label'])\n",
    "\n",
    "file = open(\"/Users/Owner/OneDrive/Desktop/DS_project/split_dataframe_10.csv\", 'w+', newline ='')\n",
    "\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    for prediction in labels:\n",
    "        writer.writerow([prediction])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =  relevance_pipeline(split_dataframes[11])\n",
    "\n",
    "labels = []\n",
    "\n",
    "for dict in results:\n",
    "    labels.append(dict['label'])\n",
    "\n",
    "file = open(\"/Users/Owner/OneDrive/Desktop/DS_project/split_dataframe_11.csv\", 'w+', newline ='')\n",
    "\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    for prediction in labels:\n",
    "        writer.writerow([prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =  relevance_pipeline(split_dataframes[12])\n",
    "\n",
    "labels = []\n",
    "\n",
    "for dict in results:\n",
    "    labels.append(dict['label'])\n",
    "\n",
    "file = open(\"/Users/Owner/OneDrive/Desktop/DS_project/split_dataframe_12.csv\", 'w+', newline ='')\n",
    "\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    for prediction in labels:\n",
    "        writer.writerow([prediction])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =  relevance_pipeline(split_dataframes[13])\n",
    "\n",
    "labels = []\n",
    "\n",
    "for dict in results:\n",
    "    labels.append(dict['label'])\n",
    "\n",
    "file = open(\"/Users/Owner/OneDrive/Desktop/DS_project/split_dataframe_13.csv\", 'w+', newline ='')\n",
    "\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    for prediction in labels:\n",
    "        writer.writerow([prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =  relevance_pipeline(split_dataframes[14])\n",
    "\n",
    "labels = []\n",
    "\n",
    "for dict in results:\n",
    "    labels.append(dict['label'])\n",
    "\n",
    "file = open(\"/Users/Owner/OneDrive/Desktop/DS_project/split_dataframe_14.csv\", 'w+', newline ='')\n",
    "\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    for prediction in labels:\n",
    "        writer.writerow([prediction])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =  relevance_pipeline(split_dataframes[15])\n",
    "\n",
    "labels = []\n",
    "\n",
    "for dict in results:\n",
    "    labels.append(dict['label'])\n",
    "\n",
    "file = open(\"/Users/Owner/OneDrive/Desktop/DS_project/split_dataframe_15.csv\", 'w+', newline ='')\n",
    "\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    for prediction in labels:\n",
    "        writer.writerow([prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =  relevance_pipeline(split_dataframes[16])\n",
    "\n",
    "labels = []\n",
    "\n",
    "for dict in results:\n",
    "    labels.append(dict['label'])\n",
    "\n",
    "file = open(\"/Users/Owner/OneDrive/Desktop/DS_project/split_dataframe_16.csv\", 'w+', newline ='')\n",
    "\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    for prediction in labels:\n",
    "        writer.writerow([prediction])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =  relevance_pipeline(split_dataframes[17])\n",
    "\n",
    "labels = []\n",
    "\n",
    "for dict in results:\n",
    "    labels.append(dict['label'])\n",
    "\n",
    "file = open(\"/Users/Owner/OneDrive/Desktop/DS_project/split_dataframe_17.csv\", 'w+', newline ='')\n",
    "\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    for prediction in labels:\n",
    "        writer.writerow([prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =  relevance_pipeline(split_dataframes[18])\n",
    "\n",
    "labels = []\n",
    "\n",
    "for dict in results:\n",
    "    labels.append(dict['label'])\n",
    "\n",
    "file = open(\"/Users/Owner/OneDrive/Desktop/DS_project/split_dataframe_18.csv\", 'w+', newline ='')\n",
    "\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    for prediction in labels:\n",
    "        writer.writerow([prediction])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =  relevance_pipeline(split_dataframes[19])\n",
    "\n",
    "labels = []\n",
    "\n",
    "for dict in results:\n",
    "    labels.append(dict['label'])\n",
    "\n",
    "file = open(\"/Users/Owner/OneDrive/Desktop/DS_project/split_dataframe_19.csv\", 'w+', newline ='')\n",
    "\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    for prediction in labels:\n",
    "        writer.writerow([prediction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rejoining dfs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_number(filename):\n",
    "    return int(re.findall(r'\\d+', filename)[0])\n",
    "\n",
    "df_files = glob.glob('/Users/Owner/OneDrive/Desktop/DS_project/relevance/*.{}'.format('csv'))\n",
    "df_sorted = sorted(df_files, key = extract_number)\n",
    "df_combined = pd.concat([pd.read_csv(file, header=None) for file in df_sorted], ignore_index=True)\n",
    "df_combined.columns = [\"relevance\"]\n",
    "\n",
    "full_data['covid_relevance'] = df_combined['relevance']\n",
    "full_data['covid_relevance'] = full_data['covid_relevance'].replace({'LABEL_0':'Negative', 'LABEL_1':'Positive'})\n",
    "\n",
    "full_data.to_csv(\"/Users/Owner/OneDrive/Desktop/DS_project/covid_relevance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pa.Table.from_pandas(full_data)\n",
    "\n",
    "pq.write_table(table, \"/Users/Owner/OneDrive/Desktop/DS_project/covid_relevance.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "714965\n"
     ]
    }
   ],
   "source": [
    "positives = ['Positive']\n",
    "covid_tweets = full_data[full_data['covid_relevance'].isin(positives)]\n",
    "print(len(covid_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_splits = data_split(covid_tweets, 'text', 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =  sentiment_pipeline(covid_splits[0])\n",
    "\n",
    "labels = []\n",
    "\n",
    "for dict in results:\n",
    "    labels.append(dict['label'])\n",
    "\n",
    "file = open(\"/Users/Owner/OneDrive/Desktop/DS_project/covid_dataframe_0.csv\", 'w+', newline ='')\n",
    "\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    for prediction in labels:\n",
    "        writer.writerow([prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =  sentiment_pipeline(covid_splits[1])\n",
    "\n",
    "labels = []\n",
    "\n",
    "for dict in results:\n",
    "    labels.append(dict['label'])\n",
    "\n",
    "file = open(\"/Users/Owner/OneDrive/Desktop/DS_project/covid_dataframe_1.csv\", 'w+', newline ='')\n",
    "\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    for prediction in labels:\n",
    "        writer.writerow([prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =  sentiment_pipeline(covid_splits[2])\n",
    "\n",
    "labels = []\n",
    "\n",
    "for dict in results:\n",
    "    labels.append(dict['label'])\n",
    "\n",
    "file = open(\"/Users/Owner/OneDrive/Desktop/DS_project/covid_dataframe_2.csv\", 'w+', newline ='')\n",
    "\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    for prediction in labels:\n",
    "        writer.writerow([prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =  sentiment_pipeline(covid_splits[3])\n",
    "\n",
    "labels = []\n",
    "\n",
    "for dict in results:\n",
    "    labels.append(dict['label'])\n",
    "\n",
    "file = open(\"/Users/Owner/OneDrive/Desktop/DS_project/covid_dataframe_3.csv\", 'w+', newline ='')\n",
    "\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    for prediction in labels:\n",
    "        writer.writerow([prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =  sentiment_pipeline(covid_splits[4])\n",
    "\n",
    "labels = []\n",
    "\n",
    "for dict in results:\n",
    "    labels.append(dict['label'])\n",
    "\n",
    "file = open(\"/Users/Owner/OneDrive/Desktop/DS_project/covid_dataframe_4.csv\", 'w+', newline ='')\n",
    "\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    for prediction in labels:\n",
    "        writer.writerow([prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =  sentiment_pipeline(covid_splits[5])\n",
    "\n",
    "labels = []\n",
    "\n",
    "for dict in results:\n",
    "    labels.append(dict['label'])\n",
    "\n",
    "file = open(\"/Users/Owner/OneDrive/Desktop/DS_project/covid_dataframe_5.csv\", 'w+', newline ='')\n",
    "\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    for prediction in labels:\n",
    "        writer.writerow([prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =  sentiment_pipeline(covid_splits[6])\n",
    "\n",
    "labels = []\n",
    "\n",
    "for dict in results:\n",
    "    labels.append(dict['label'])\n",
    "\n",
    "file = open(\"/Users/Owner/OneDrive/Desktop/DS_project/covid_dataframe_6.csv\", 'w+', newline ='')\n",
    "\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    for prediction in labels:\n",
    "        writer.writerow([prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =  sentiment_pipeline(covid_splits[7])\n",
    "\n",
    "labels = []\n",
    "\n",
    "for dict in results:\n",
    "    labels.append(dict['label'])\n",
    "\n",
    "file = open(\"/Users/Owner/OneDrive/Desktop/DS_project/covid_dataframe_7.csv\", 'w+', newline ='')\n",
    "\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    for prediction in labels:\n",
    "        writer.writerow([prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =  sentiment_pipeline(covid_splits[8])\n",
    "\n",
    "labels = []\n",
    "\n",
    "for dict in results:\n",
    "    labels.append(dict['label'])\n",
    "\n",
    "file = open(\"/Users/Owner/OneDrive/Desktop/DS_project/covid_dataframe_8.csv\", 'w+', newline ='')\n",
    "\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    for prediction in labels:\n",
    "        writer.writerow([prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =  sentiment_pipeline(covid_splits[9])\n",
    "\n",
    "labels = []\n",
    "\n",
    "for dict in results:\n",
    "    labels.append(dict['label'])\n",
    "\n",
    "file = open(\"/Users/Owner/OneDrive/Desktop/DS_project/covid_dataframe_9.csv\", 'w+', newline ='')\n",
    "\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    for prediction in labels:\n",
    "        writer.writerow([prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =  sentiment_pipeline(covid_splits[10])\n",
    "\n",
    "labels = []\n",
    "\n",
    "for dict in results:\n",
    "    labels.append(dict['label'])\n",
    "\n",
    "file = open(\"/Users/Owner/OneDrive/Desktop/DS_project/covid_dataframe_10.csv\", 'w+', newline ='')\n",
    "\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    for prediction in labels:\n",
    "        writer.writerow([prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =  sentiment_pipeline(covid_splits[11])\n",
    "\n",
    "labels = []\n",
    "\n",
    "for dict in results:\n",
    "    labels.append(dict['label'])\n",
    "\n",
    "file = open(\"/Users/Owner/OneDrive/Desktop/DS_project/covid_dataframe_11.csv\", 'w+', newline ='')\n",
    "\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    for prediction in labels:\n",
    "        writer.writerow([prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =  sentiment_pipeline(covid_splits[12])\n",
    "\n",
    "labels = []\n",
    "\n",
    "for dict in results:\n",
    "    labels.append(dict['label'])\n",
    "\n",
    "file = open(\"/Users/Owner/OneDrive/Desktop/DS_project/covid_dataframe_12.csv\", 'w+', newline ='')\n",
    "\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    for prediction in labels:\n",
    "        writer.writerow([prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =  sentiment_pipeline(covid_splits[13])\n",
    "\n",
    "labels = []\n",
    "\n",
    "for dict in results:\n",
    "    labels.append(dict['label'])\n",
    "\n",
    "file = open(\"/Users/Owner/OneDrive/Desktop/DS_project/covid_dataframe_13.csv\", 'w+', newline ='')\n",
    "\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    for prediction in labels:\n",
    "        writer.writerow([prediction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rejoining covid dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_tweets = full_data[full_data['covid_relevance'] == 'Positive'].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_files = glob.glob('/Users/Owner/OneDrive/Desktop/DS_project/covid/*.{}'.format('csv'))\n",
    "\n",
    "covid_sorted = sorted(covid_files, key = extract_number)\n",
    "covid_combined = pd.concat([pd.read_csv(file, header=None) for file in covid_sorted], ignore_index=True)\n",
    "covid_combined.columns = [\"covid_sentiment\"]\n",
    "\n",
    "covid_tweets['covid_sentiment'] = covid_combined['covid_sentiment']\n",
    "covid_tweets['covid_sentiment'] = covid_tweets['covid_sentiment'].replace({'LABEL_0':'Neutral', 'LABEL_1':'Positive', \"LABEL_2\":'Negatve'})\n",
    "\n",
    "covid_tweets.to_csv(\"/Users/Owner/OneDrive/Desktop/DS_project/covid_sentiment.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pa.Table.from_pandas(covid_tweets)\n",
    "\n",
    "pq.write_table(table, \"/Users/Owner/OneDrive/Desktop/DS_project/covid_sentiment.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psych750",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
